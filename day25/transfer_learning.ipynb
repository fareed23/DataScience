{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transfer Learning in Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is transfer learning and how it works?`\n",
    "\n",
    "The reuse of a pre-trained model on a new problem is known as transfer learning in machine learning. A machine uses the knowledge learned from a prior assignment to increase prediction about a new task in transfer learning. You could, for example, use the information gained during training to distinguish beverages when training a classifier to predict whether an image contains cuisine.\n",
    "\n",
    "`How it works?`\n",
    "\n",
    "In computer vision, neural networks typically aim to detect edges in the first layer, forms in the middle layer, and task-specific features in the latter layers.\n",
    "\n",
    "The early and central layers are employed in transfer learning, and the latter layers are only retrained. It makes use of the labelled data from the task it was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Why Should You Use Transfer Learning?`\n",
    "\n",
    "Transfer learning offers a number of advantages, the most important of which are reduced training time, improved neural network performance (in most circumstances), and the absence of a large amount of data.\n",
    "\n",
    "To train a neural model from scratch, a lot of data is typically needed, but access to that data isn’t always possible – this is when transfer learning comes in handy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Steps to Use Transfer Learning:`\n",
    "\n",
    "1. Training a Model to Reuse it\n",
    "2. Using a Pre Trained Model\n",
    "3. Extraction of Features\n",
    "4. Extraction of Features in Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.efficientnet import EfficientNetB7\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Data Augmentation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocess_input,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range=0.2,\n",
    "                             validation_split=0.2,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './coffee.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: './coffee.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training_generator \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     dir_path,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     target_size\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m,\u001b[39m224\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m validation_generator \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     dir_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[39m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1649\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[1;32m   1650\u001b[0m         directory,\n\u001b[1;32m   1651\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1652\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[1;32m   1653\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[1;32m   1654\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[1;32m   1655\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[1;32m   1656\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[1;32m   1657\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[1;32m   1658\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1659\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1660\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   1661\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[1;32m   1662\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[1;32m   1663\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[1;32m   1664\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[1;32m   1665\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[1;32m   1666\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m   1667\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m   1668\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/keras/src/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[1;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './coffee.jpeg'"
     ]
    }
   ],
   "source": [
    "training_generator = datagen.flow_from_directory(\n",
    "    dir_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dir_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20024384 (76.39 MB)\n",
      "Trainable params: 20024384 (76.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Classifier\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(units=512, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(units=512, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output  = layers.Dense(units=5, activation='softmax')(x)\n",
    "model = models.Model(base_model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20552261 (78.40 MB)\n",
      "Trainable params: 527877 (2.01 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('./model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_acc', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fareed/Documents/Python/python_datascience/day25/transfer_learning.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(training_generator, validation_data\u001b[39m=\u001b[39mvalidation_generator, epochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, callbacks\u001b[39m=\u001b[39m[early_stopping, checkpoint, model_checkpoint])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_generator, validation_data=validation_generator, epochs=2, callbacks=[early_stopping, checkpoint, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
